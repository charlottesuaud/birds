{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2be3a07e-004b-46b8-8982-a3ce28119847",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "002874a1-2822-4edc-af34-cc582c08d1ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T16:59:08.313142Z",
     "start_time": "2021-05-25T16:59:05.588449Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01fc8356-0fa8-4f66-9984-8d0134f8fd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4bcb3ee-9ff8-4545-b333-32135288a7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2f748ff-2df5-4f1e-99e3-d70f3e01a319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3ba73a41-1686-4955-9e92-4eaf210212a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from birds.data.spectrogram import generate_tensor, generate_spectrogram\n",
    "from birds.data.spectrogram import generate_mel_spectrogram, generate_db_scale_mel_spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2140978b-08fd-4e44-9af1-1091bfbf126d",
   "metadata": {},
   "source": [
    "# First pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd82af24-480f-46b0-961c-c60c9ab3be62",
   "metadata": {},
   "source": [
    "## Try with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6716700f-26f6-40d1-8056-f810f4283e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(file_name, label):\n",
    "    image = tf.io.read_file(directory_0 + file_name)\n",
    "    image = tf.io.decode_image(image, channels=1, dtype=tf.float32)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2c8b2d4-fff6-4375-b1d0-50b9356899bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((), ()), types: (tf.string, tf.int64)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory_0 = '/Users/Charlotte/Desktop/Photos/'\n",
    "\n",
    "df_0 = pd.read_csv(directory_0 + 'train.csv')\n",
    "\n",
    "file_paths_0 = df_0['file_name'].values\n",
    "labels_0 = df_0['label'].values\n",
    "\n",
    "ds_train_0 = tf.data.Dataset.from_tensor_slices((file_paths_0, labels_0))\n",
    "ds_train_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af601ec4-fcd2-4335-a587-3d7ec33231bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: (<unknown>, (None,)), types: (tf.float32, tf.int64)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train_0 = ds_train_0.map(read_image).batch(2)\n",
    "ds_train_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8ca1e4-93f1-405f-abe1-e5d1710f114b",
   "metadata": {},
   "source": [
    "## Try with audio files // test in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c477e7f2-deb4-40f2-83fd-012879d7f173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mel_spectrogram_test(file_path, label):\n",
    "    audio = tfio.audio.AudioIOTensor(file_path, dtype='float32')\n",
    "    tensor = audio.to_tensor()\n",
    "    input_rate = tf.cast(audio.rate, tf.int64)\n",
    "    resample_tensor = tfio.audio.resample(tensor, input_rate, 16_000, name=None)\n",
    "    split_tensor = resample_tensor[:160_000]\n",
    "    harmonized_tensor = tf.reduce_mean(split_tensor, 1)\n",
    "    spectrogram = tfio.audio.spectrogram(harmonized_tensor, nfft=2048, window=256, stride=256)\n",
    "    mel_spectrogram = tfio.audio.melscale(spectrogram, rate=16_000, mels=128, fmin=0, fmax=8000)\n",
    "    return tf.transpose(mel_spectrogram, perm=[1, 0]), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0287294-5fab-431c-8cf5-14f48c1deced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: ((), ()), types: (tf.string, tf.int64)>\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "<BatchDataset shapes: ((None, None, None), (None,)), types: (tf.float32, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "directory = '../raw_data/data_30s/train/'\n",
    "\n",
    "df = pd.read_csv(directory + 'y_train.csv')\n",
    "\n",
    "file_paths = df['Path'].values\n",
    "labels = df['Target'].values\n",
    "\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
    "print(ds_train)\n",
    "\n",
    "ds_train = ds_train.map(generate_mel_spectrogram_test).batch(1)\n",
    "print(ds_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11350b03-0ed4-4c05-81e6-2b1962d1d6c0",
   "metadata": {},
   "source": [
    "## Try with audio files // import functions from `spectrogram.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d70ae0f-6ce2-410c-9da7-b5b5b62a9744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: ((), ()), types: (tf.string, tf.int64)>\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n",
      "<BatchDataset shapes: ((None, None, None), (None,)), types: (tf.float32, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "ds_train = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
    "print(ds_train)\n",
    "\n",
    "ds_train = ds_train.map(generate_mel_spectrogram).batch(1)\n",
    "print(ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa49a5d6-55c3-4b22-977a-f64b45965665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
